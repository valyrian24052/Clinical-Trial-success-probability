{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch -q"
      ],
      "metadata": {
        "id": "D1JJoQj4dzvI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import joblib\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "5ebRJ0gnoOHZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FILE_PATH = '/content/Processed_Train_clinical_trials_data.xlsx'\n",
        "MODEL_SAVE_PATH = 'clinical_trial_predictor.pkl'"
      ],
      "metadata": {
        "id": "vWEgNbdiojIU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = '/content/Processed_Test_clinical_trials_data.xlsx'\n",
        "PREDICTIONS_SAVE_PATH = 'test_data_predictions.csv'"
      ],
      "metadata": {
        "id": "LzJdf0Iuo7Jl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom scikit-learn transformer to generate text embeddings using a\n",
        "    pre-trained Transformer model from Hugging Face.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name='distilbert-base-uncased', batch_size=32):\n",
        "        self.model_name = model_name\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = AutoModel.from_pretrained(self.model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Generates embeddings for the input text data.\n",
        "        \"\"\"\n",
        "        if not isinstance(X, pd.Series):\n",
        "            X = pd.Series(X)\n",
        "\n",
        "        all_embeddings = []\n",
        "        print(f\"Generating embeddings with {self.model_name} on {self.device}...\")\n",
        "        for i in tqdm(range(0, len(X), self.batch_size)):\n",
        "            batch = X[i:i+self.batch_size].fillna('').tolist()\n",
        "            inputs = self.tokenizer(\n",
        "                batch, return_tensors='pt', truncation=True, padding=True, max_length=512\n",
        "            ).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_embeddings.append(cls_embeddings)\n",
        "\n",
        "        return np.concatenate(all_embeddings, axis=0)"
      ],
      "metadata": {
        "id": "txIuFgHYoOJ5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ClinicalTrialPredictor:\n",
        "    \"\"\"\n",
        "    A complete pipeline to train a model for predicting clinical trial outcomes\n",
        "    and make predictions on new data.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.pipeline = None\n",
        "        self._define_feature_sets()\n",
        "\n",
        "    def _define_feature_sets(self):\n",
        "        \"\"\"\n",
        "        Defines the column lists for different feature types.\n",
        "        \"\"\"\n",
        "        self.numeric_features = [\n",
        "            'Has_Results', 'Low_Enrollment', 'Results_Delay_Days', 'Suspended_Terminated'\n",
        "        ]\n",
        "        self.categorical_features = [\n",
        "            'Sponsor', 'Funder Type', 'Allocation', 'Intervention Model', 'Masking',\n",
        "            'Primary Purpose', 'BIOLOGICAL_1', 'COMBINATION_PRODUCT_1', 'DEVICE_1',\n",
        "            'DRUG_1', 'DRUG_2', 'DRUG_3', 'OTHER_1', 'OTHER_2',\n",
        "            'PROCEDURE_1', 'RADIATION_1'\n",
        "        ]\n",
        "        self.text_features = ['Conditions', 'Study_Context', 'Outcome_Details']\n",
        "\n",
        "    def _create_pipeline(self):\n",
        "        \"\"\"\n",
        "        Builds the full scikit-learn pipeline, including preprocessing for all\n",
        "        data types and the final estimator model.\n",
        "        \"\"\"\n",
        "        numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median'))])\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
        "        ])\n",
        "\n",
        "        conditions_transformer = Pipeline(steps=[('embeddings', TextEmbeddingTransformer())])\n",
        "        context_transformer = Pipeline(steps=[('embeddings', TextEmbeddingTransformer())])\n",
        "        outcome_transformer = Pipeline(steps=[('embeddings', TextEmbeddingTransformer())])\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numeric_transformer, self.numeric_features),\n",
        "                ('cat', categorical_transformer, self.categorical_features),\n",
        "                ('cond_emb', conditions_transformer, 'Conditions'),\n",
        "                ('cont_emb', context_transformer, 'Study_Context'),\n",
        "                ('outc_emb', outcome_transformer, 'Outcome_Details')\n",
        "            ],\n",
        "            remainder='drop'\n",
        "        )\n",
        "\n",
        "        self.pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LGBMClassifier(class_weight='balanced', random_state=42))\n",
        "        ])\n",
        "\n",
        "    def train(self, train_filepath):\n",
        "        \"\"\"\n",
        "        Loads training data, splits it for validation, trains the pipeline,\n",
        "        and evaluates its performance.\n",
        "        \"\"\"\n",
        "        print(\"--- Starting Training Process ---\")\n",
        "        df = pd.read_excel(train_filepath)\n",
        "\n",
        "        y = df['Outcome_numeric']\n",
        "        X = df.drop(columns=['Outcome_numeric', 'Outcome'])\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        self._create_pipeline()\n",
        "\n",
        "        print(\"\\nTraining model on the training set...\")\n",
        "        self.pipeline.fit(X_train, y_train)\n",
        "\n",
        "        print(\"\\nEvaluating model on the validation set...\")\n",
        "        y_pred = self.pipeline.predict(X_test)\n",
        "        print(\"\\n--- Validation Classification Report ---\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        print(\"\\nRe-training model on the full dataset...\")\n",
        "        self.pipeline.fit(X, y)\n",
        "        print(\"Training complete. Model is ready.\")\n",
        "\n",
        "    def predict(self, test_filepath, output_csv_path='predictions.csv'):\n",
        "        \"\"\"\n",
        "        Loads new data, predicts the outcome, calculates the probability of\n",
        "        FAILURE on a 0-100 scale, and saves the results to a CSV file.\n",
        "        \"\"\"\n",
        "        if self.pipeline is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Please call the 'train' method first.\")\n",
        "\n",
        "        print(f\"\\n--- Making predictions on new data from {test_filepath} ---\")\n",
        "        df_test = pd.read_excel(test_filepath)\n",
        "\n",
        "        predictions_numeric = self.pipeline.predict(df_test)\n",
        "        predicted_probabilities = self.pipeline.predict_proba(df_test)\n",
        "\n",
        "        failure_probabilities = (predicted_probabilities[:, 1] * 100).round(2)\n",
        "\n",
        "        df_test['Outcome_numeric'] = predictions_numeric\n",
        "        df_test['Failure_Probability'] = failure_probabilities\n",
        "        df_test['Outcome'] = df_test['Outcome_numeric'].apply(lambda x: 'Fail' if x == 1 else 'Approved')\n",
        "\n",
        "        df_test.to_csv(output_csv_path, index=False)\n",
        "        print(f\"Predictions saved successfully to {output_csv_path}\")\n",
        "        return df_test\n",
        "\n",
        "    def save_model(self, filepath='clinical_trial_predictor.pkl'):\n",
        "        \"\"\"\n",
        "        Saves the entire trained pipeline to a file.\n",
        "        \"\"\"\n",
        "        if self.pipeline is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Cannot save an empty model.\")\n",
        "\n",
        "        print(f\"\\nSaving model to {filepath}...\")\n",
        "        joblib.dump(self.pipeline, filepath)\n",
        "        print(\"Model saved successfully.\")\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_file(cls, filepath):\n",
        "        \"\"\"\n",
        "        Loads a pre-trained pipeline from a file and returns a new instance\n",
        "        of the predictor class.\n",
        "        \"\"\"\n",
        "        print(f\"Loading model from {filepath}...\")\n",
        "        pipeline = joblib.load(filepath)\n",
        "        predictor = cls()\n",
        "        predictor.pipeline = pipeline\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return predictor"
      ],
      "metadata": {
        "id": "9zPBjEFVoOM_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ClinicalTrialPredictor()\n",
        "predictor.train(TRAIN_FILE_PATH)\n",
        "predictor.save_model(MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM3GBcEDoOPc",
        "outputId": "e47db2b7-9249-4dc4-b485-c50d8637bf05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training Process ---\n",
            "\n",
            "Training model on the training set...\n",
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 17.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:13<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 614, number of negative: 404\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074875 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 587761\n",
            "[LightGBM] [Info] Number of data points in the train set: 1018, number of used features: 2342\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Evaluating model on the validation set...\n",
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 17.49it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:02<00:00,  3.18it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:05<00:00,  1.49it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Validation Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.63      0.64       101\n",
            "           1       0.76      0.77      0.77       154\n",
            "\n",
            "    accuracy                           0.72       255\n",
            "   macro avg       0.70      0.70      0.70       255\n",
            "weighted avg       0.72      0.72      0.72       255\n",
            "\n",
            "\n",
            "Re-training model on the full dataset...\n",
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:02<00:00, 19.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 768, number of negative: 505\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 587822\n",
            "[LightGBM] [Info] Number of data points in the train set: 1273, number of used features: 2350\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Training complete. Model is ready.\n",
            "\n",
            "Saving model to clinical_trial_predictor.pkl...\n",
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_predictor = ClinicalTrialPredictor.load_from_file(MODEL_SAVE_PATH)\n",
        "prediction_results = loaded_predictor.predict(TEST_FILE_PATH, PREDICTIONS_SAVE_PATH)\n",
        "\n",
        "print(\"\\n--- Prediction Results (First 5 Rows) ---\")\n",
        "print(prediction_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqQn0uuuoOR5",
        "outputId": "3ff6b0f7-4fd4-44aa-bd7d-c2173147d642"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from clinical_trial_predictor.pkl...\n",
            "Model loaded successfully.\n",
            "\n",
            "--- Making predictions on new data from /content/Processed_Test_clinical_trials_data.xlsx ---\n",
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 23.10it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:03<00:00,  2.81it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:04<00:00,  1.84it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 24.89it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:03<00:00,  2.72it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with distilbert-base-uncased on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:04<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved successfully to test_data_predictions.csv\n",
            "\n",
            "--- Prediction Results (First 5 Rows) ---\n",
            "    NCT Number  Has_Results  Low_Enrollment  Results_Delay_Days  \\\n",
            "0  NCT03765918            0               0                  -1   \n",
            "1  NCT05572515            0               0                  -1   \n",
            "2  NCT05057494            0               0                  -1   \n",
            "3  NCT05020236            0               0                  -1   \n",
            "4  NCT06091865            0               0                  -1   \n",
            "\n",
            "   Suspended_Terminated                                         Conditions  \\\n",
            "0                     0                            Head and Neck Neoplasms   \n",
            "1                     0            Relapsed or Refractory Multiple Myeloma   \n",
            "2                     0  Chronic Lymphocytic Leukemia or Small Lymphocy...   \n",
            "3                     0                                   Multiple Myeloma   \n",
            "4                     0              Diffuse Large B-cell Lymphoma (DLBCL)   \n",
            "\n",
            "                                       Study_Context  \\\n",
            "0  Study of Pembrolizumab Given Prior to Surgery ...   \n",
            "1  A Study Comparing Teclistamab Monotherapy Vers...   \n",
            "2  A Study of Acalabrutinib Plus Venetoclax Versu...   \n",
            "3  A Study to Learn About the Study Medicine Elra...   \n",
            "4  A Study to Compare How Well Odronextamab Combi...   \n",
            "\n",
            "                                     Outcome_Details  \\\n",
            "0  Event-free Survival (EFS), EFS is the time fro...   \n",
            "1  Part 1: Progression-free Survival (PFS), PFS i...   \n",
            "2  Progression-free Survival (PFS), To assess whe...   \n",
            "3  Part 1 Safety Lead-In: Incidence of dose limit...   \n",
            "4  Incidence of dose limiting toxicities (DLTs), ...   \n",
            "\n",
            "                               Sponsor Funder Type  ...                DRUG_1  \\\n",
            "0              Merck Sharp & Dohme LLC    INDUSTRY  ...  Cisplatin 100 mg/m^2   \n",
            "1  Janssen Research & Development, LLC    INDUSTRY  ...           Teclistamab   \n",
            "2                          AstraZeneca    INDUSTRY  ...         Acalabrutinib   \n",
            "3                               Pfizer    INDUSTRY  ...           Elranatamab   \n",
            "4            Regeneron Pharmaceuticals    INDUSTRY  ...          Odronextamab   \n",
            "\n",
            "         DRUG_2            DRUG_3 OTHER_1 OTHER_2 PROCEDURE_1  \\\n",
            "0           NaN               NaN     NaN     NaN         NaN   \n",
            "1  Pomalidomide        Bortezomib     NaN     NaN         NaN   \n",
            "2    Venetoclax      Obinutuzumab     NaN     NaN         NaN   \n",
            "3   Daratumumab      Pomalidomide     NaN     NaN         NaN   \n",
            "4     Rituximab  Cyclophosphamide     NaN     NaN         NaN   \n",
            "\n",
            "            RADIATION_1 Outcome_numeric Failure_Probability   Outcome  \n",
            "0  Radiotherapy 60 Gray               1               89.36      Fail  \n",
            "1                   NaN               1               53.94      Fail  \n",
            "2                   NaN               0               30.00  Approved  \n",
            "3                   NaN               0               48.04  Approved  \n",
            "4                   NaN               0               41.39  Approved  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}